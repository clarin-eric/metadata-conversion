<?xml version='1.0' encoding='UTF-8'?><resource xmlns="http://datacite.org/schema/kernel-4" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://datacite.org/schema/kernel-4 http://schema.datacite.org/meta/kernel-4.1/metadata.xsd"><identifier identifierType="DOI">10.18710/7TSABU</identifier><creators><creator><creatorName nameType="Personal">Lorenz, David</creatorName><givenName>David</givenName><familyName>Lorenz</familyName><nameIdentifier nameIdentifierScheme="ORCID">0000-0002-7451-099X</nameIdentifier><affiliation>Universität Rostock</affiliation></creator><creator><creatorName nameType="Personal">Tizón-Couto, David</creatorName><givenName>David</givenName><familyName>Tizón-Couto</familyName><nameIdentifier nameIdentifierScheme="ORCID">0000-0003-0788-7954</nameIdentifier><affiliation>Universidade de Vigo</affiliation></creator></creators><titles><title>Replication data for: Chunking or predicting – frequency information and reduction in the perception of multi-word sequences</title></titles><publisher>DataverseNO</publisher><publicationYear>2019</publicationYear><subjects><subject>Arts and Humanities</subject><subject>speech perception</subject><subject>phonetic reduction</subject><subject>chunking</subject><subject>frequency information</subject><subject>entrenchment</subject><subject>English</subject></subjects><contributors><contributor contributorType="ContactPerson"><contributorName nameType="Personal">Lorenz, David</contributorName><givenName>David</givenName><familyName>Lorenz</familyName><affiliation>Universität Rostock</affiliation></contributor><contributor contributorType="Producer"><contributorName>Albert-Ludwigs-Universität Freiburg</contributorName></contributor><contributor contributorType="Producer"><contributorName nameType="Personal">Universidade de Vigo</contributorName><givenName>de</givenName><familyName>versidade de Vigo</familyName></contributor><contributor contributorType="Distributor"><contributorName nameType="Personal">The Tromsø Repository of Language and Linguistics</contributorName><givenName>The</givenName><familyName>Tromsø Repository of Language and Linguistics</familyName></contributor></contributors><dates><date dateType="Created">2016</date><date dateType="Submitted">2019-04-18</date><date dateType="Updated">2019-06-06</date><date dateType="Collected">2016-05-09/2016-11-24</date></dates><resourceType resourceTypeGeneral="Dataset">experimental data</resourceType><sizes><size>8470</size><size>25648</size><size>316412</size><size>31345</size><size>575470</size><size>369845</size><size>599815</size><size>352431</size></sizes><formats><format>text/plain</format><format>text/plain</format><format>application/x-rlang-transport</format><format>text/plain</format><format>text/tab-separated-values</format><format>text/tab-separated-values</format><format>text/tab-separated-values</format><format>text/tab-separated-values</format></formats><version>1.1</version><rightsList><rights rightsURI="info:eu-repo/semantics/openAccess"/><rights rightsURI="https://creativecommons.org/publicdomain/zero/1.0/">CC0 Waiver</rights></rightsList><descriptions><description descriptionType="Abstract">&lt;p>This is the data and code from a word-monitoring task, in which participants responded to the word 'to' in verb + to-infinitive structures (V-to-Vinf) in English, where 'to' could occur in a full or reduced pronunciation. Accuracy and response times were analysed with mixed-effects generalized additive models (GAMM); the code also includes visualisations of these models. The paper is accepted for publication in Cognitive Linguistics.&#xd;
The experiment was run with OpenSesame (version 3.0.7 for Mac, cf. Mathôt et al. 2012). The data include information on frequencies of occurrence of words and bigrams; this was extracted from the Corpus of Contemporary American English (COCA, Davies 2008–). We used R (R Core Team 2017) for all data analyses, hence the code can best be replicated in R. &lt;/p>&lt;p>&lt;/p>&#xd;
&#xd;
&#xd;
&lt;p>Abstract:&#xd;
Frequently used linguistic structures become entrenched in memory; this is often assumed to make their consecutive parts more predictable, as well as fuse them into a single unit (chunking). High frequency moreover leads to a propensity for phonetic reduction. We present a word recognition experiment which tests how frequency information (string frequency, transitional probability) interacts with reduction in speech perception. Detection of the element to is tested in V-to-Vinf sequences in English (e.g. need to Vinf), where to can undergo reduction (“needa”). Results show that reduction impedes recognition, but this can be mitigated by the predictability of the item. Recognition generally benefits from surface frequency, while a modest chunking effect is found in delayed responses to reduced forms of high-frequency items. Transitional probability shows a facilitating effect on reduced but not on full forms. Reduced forms also pose more difficulty when the phonological context obscures the onset of to. We conclude that listeners draw on frequency information in a predictive manner to cope with reduction. High-frequency structures are not inevitably perceived as chunks, but depend on cues in the phonetic form – reduction leads to perceptual prominence of the whole over the parts and thus promotes a holistic access.&lt;/p></description><description descriptionType="TechnicalInfo">OpenSesame, 3.0.7.</description></descriptions><geoLocations><geoLocation><geoLocationPlace>Freiburg, Vigo</geoLocationPlace></geoLocation></geoLocations><fundingReferences><fundingReference><funderName>Spanish Ministry of Economy and Competitiveness</funderName><awardNumber>FFI2016-77018-P</awardNumber></fundingReference><fundingReference><funderName>European Regional Development Fund</funderName><awardNumber>IJCI-2015-25843</awardNumber></fundingReference><fundingReference><funderName>Xunta de Galicia</funderName><awardNumber>ED431C 2017/50</awardNumber></fundingReference><fundingReference><funderName>Wissenschaftliche Gesellschaft Freiburg</funderName></fundingReference></fundingReferences></resource>